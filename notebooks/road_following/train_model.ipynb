{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Follower - Train Model(モデルの学習)\n",
    "\n",
    "In this notebook we will train a neural network to take an input image, and output a set of x, y values corresponding to a target.\n",
    "\n",
    "(訳) このnotebookは、入力画像を読み込み、ターゲットに対応するx、y値のセットを出力するようにニューラルネットワークを学習します。\n",
    "\n",
    "We will be using PyTorch deep learning framework to train ResNet18 neural network architecture model for road follower application.\n",
    "\n",
    "(訳) road followerアプリのためにResNet18 neural networkアーキテクチャーモデルを学習するために、PyTorch deep learningフレームワークを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Using cached https://files.pythonhosted.org/packages/e1/c1/bc1dba38b48f4ae3c4428aea669c5e27bd5a7642a74c8348451e0bd8ff86/tqdm-4.36.1-py2.py3-none-any.whl\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.36.1\n"
     ]
    }
   ],
   "source": [
    "! pip3 install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "import PIL.Image\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset Instance(データセットインスタンスの作成)\n",
    "\n",
    "Here we create a custom ``torch.utils.data.Dataset`` implementation, which implements the ``__len__`` and ``__getitem__`` functions.  This class\n",
    "is responsible for loading images and parsing the x, y values from the image filenames.  Because we implement the ``torch.utils.data.Dataset`` class,\n",
    "we can use all of the torch data utilities :)\n",
    "\n",
    "(訳) ``__len__`` と ``__getitem__``関数が実装されたカスタマイズされた``torch.utils.data.Dataset`` の実装を生成します。このクラスは、画像をロードするための役割と、画像ファイル名からx、y値の値をパースして取得します。`torch.utils.data.Dataset``を実装する事で、すべてのtorchデータユーティリティを使用する事ができます。\n",
    "\n",
    "We hard coded some transformations (like color jitter) into our dataset.  We made random horizontal flips optional (in case you want to follow a non-symmetric path, like a road\n",
    "where we need to 'stay right').  If it doesn't matter whether your robot follows some convention, you could enable flips to augment the dataset.\n",
    "\n",
    "(訳) いくつかの変換（カラージッターなど）をデータセットにハードコーディングしました。ランダムな水平反転をオプションにしました（「右にとどまる」必要がある道路のように、非対称の経路をたどる場合）。ロボットが何らかの規則に従っているかどうかが重要でない場合は、フリップを有効にしてデータセットを拡張できます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(path):\n",
    "    \"\"\"Gets the x value from the image filename\"\"\"\n",
    "    return (float(int(path[3:6])) - 50.0) / 50.0\n",
    "\n",
    "def get_y(path):\n",
    "    \"\"\"Gets the y value from the image filename\"\"\"\n",
    "    return (float(int(path[7:10])) - 50.0) / 50.0\n",
    "\n",
    "class XYDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, directory, random_hflips=False):\n",
    "        self.directory = directory\n",
    "        self.random_hflips = random_hflips\n",
    "        self.image_paths = glob.glob(os.path.join(self.directory, '*.jpg'))\n",
    "        self.color_jitter = transforms.ColorJitter(0.3, 0.3, 0.3, 0.3)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        \n",
    "        image = PIL.Image.open(image_path)\n",
    "        x = float(get_x(os.path.basename(image_path)))\n",
    "        y = float(get_y(os.path.basename(image_path)))\n",
    "        \n",
    "        if float(np.random.rand(1)) > 0.5:\n",
    "            image = transforms.functional.hflip(image)\n",
    "            x = -x\n",
    "        \n",
    "        image = self.color_jitter(image)\n",
    "        image = transforms.functional.resize(image, (224, 224))\n",
    "        image = transforms.functional.to_tensor(image)\n",
    "        image = image.numpy()[::-1].copy()\n",
    "        image = torch.from_numpy(image)\n",
    "        image = transforms.functional.normalize(image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        \n",
    "        return image, torch.tensor([x, y]).float()\n",
    "    \n",
    "dataset = XYDataset('dataset_xy', random_hflips=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train and test sets(トレーニングとテスト用のデータセットに分ける)\n",
    "Once we read dataset, we will split data set in train and test sets. In this example we split train and test a 90%-10%. The test set will be used to verify the accuracy of the model we train.\n",
    "\n",
    "データセットをロードしたら、トレーニング用とテスト用のデータセットに分割します。この例では、トレーニング用が90%, テスト用が10%で分けます。テストセットは、トレーニングするモデルの精度を検証するために使用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_percent = 0.1\n",
    "num_test = int(test_percent * len(dataset))\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - num_test, num_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data loaders to load data in batches(バッチでデータを読み込むためのdata loadersを作成)\n",
    "\n",
    "We use ``DataLoader`` class to load data in batches, shuffle data and allow using multi-subprocesses. In this example we use batch size of 64. Batch size will be based on memory available with your GPU and it can impact accuracy of the model.\n",
    "\n",
    "(訳) `` DataLoader``クラスは、並行したサブプロセスを使用して、データのシャッフル、バッチでのデータロードのために使用します。この例では、64のバッチサイズを使用します。バッチサイズは、GPUで使用可能なメモリに基づいており、モデルの精度に影響を与える可能性があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neural Network Model (Neural netwrk modelの定義)\n",
    "\n",
    "We use ResNet-18 model available on PyTorch TorchVision. \n",
    "\n",
    "(訳) PyToch TouchVisionで使用可能なResNet-18モデルを使用します。\n",
    "\n",
    "In a process called transfer learning, we can repurpose a pre-trained model (trained on millions of images) for a new task that has possibly much less data available.\n",
    "\n",
    "(訳)*転移学習*と呼ばれる手法で、利用可能なデータがはるかに少ない状態で新しいタスクをおこなうために、事前にトレーニングされたモデル（数百万の画像でトレーニングされた）を再利用する事ができます。\n",
    "\n",
    "More details on ResNet-18 : https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n",
    "\n",
    "More Details on Transfer Learning: https://www.youtube.com/watch?v=yofjFQddwHE \n",
    "\n",
    "(訳) ResNet-18の詳細: https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n",
    "\n",
    "転移学習の詳細: https://www.youtube.com/watch?v=yofjFQddwHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet model has fully connect (fc) final layer with 512 as ``in_features`` and we will be training for regression thus ``out_features`` as 1\n",
    "\n",
    "(訳) ResNetのモデルは、`in_features``として、512を最終レイヤーに全結合します。そして、``out_features``2(x,y座標)にして回帰のトレーニングをおこないます。\n",
    "\n",
    "Finally, we transfer our model for execution on the GPU\n",
    "\n",
    "最後に、GPUで実行するために、モデルを転送します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = torch.nn.Linear(512, 2)\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Regression:\n",
    "\n",
    "We train for 70 epochs and save best model if the loss is reduced. \n",
    "\n",
    "70エポック学習し、損失が減少した場合は、ベストなモデルを保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 1.263444, test_loss 18.291302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/70 [00:32<36:58, 32.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.968418, test_loss 0.262598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3/70 [01:07<27:07, 24.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.216813, test_loss 0.964457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 4/70 [01:18<22:28, 20.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.163334, test_loss 0.354809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 5/70 [01:29<19:03, 17.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.108680, test_loss 1.630302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 6/70 [01:40<16:27, 15.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.083790, test_loss 2.684981\n",
      "train loss 0.063508, test_loss 0.169249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 8/70 [01:58<12:35, 12.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.060089, test_loss 0.208757\n",
      "train loss 0.056216, test_loss 0.159305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 9/70 [02:07<11:32, 11.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.038791, test_loss 0.066456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 11/70 [02:26<10:01, 10.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.042158, test_loss 0.072030\n",
      "train loss 0.037995, test_loss 0.025546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 12/70 [02:35<09:34,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.040223, test_loss 0.019419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 14/70 [02:53<08:53,  9.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.028970, test_loss 0.028435\n",
      "train loss 0.037437, test_loss 0.013163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 16/70 [03:12<08:24,  9.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.035558, test_loss 0.037051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 17/70 [03:21<08:11,  9.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.037923, test_loss 0.037283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 18/70 [03:30<07:58,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.034203, test_loss 0.025255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 19/70 [03:39<07:45,  9.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.038991, test_loss 0.026074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 20/70 [03:48<07:35,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.043179, test_loss 0.023103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 21/70 [03:57<07:25,  9.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.031386, test_loss 0.040249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 22/70 [04:06<07:17,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.051035, test_loss 0.030277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 23/70 [04:15<07:08,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.035147, test_loss 0.032494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 24/70 [04:24<07:00,  9.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.027218, test_loss 0.027905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 25/70 [04:34<06:57,  9.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.045177, test_loss 0.031081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 26/70 [04:43<06:45,  9.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.035936, test_loss 0.026649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 27/70 [04:52<06:34,  9.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.030867, test_loss 0.018403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 28/70 [05:01<06:21,  9.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.039130, test_loss 0.060535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 29/70 [05:10<06:10,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.034376, test_loss 0.026210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 30/70 [05:19<06:02,  9.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.031472, test_loss 0.040371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 31/70 [05:28<05:52,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.035195, test_loss 0.035087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 32/70 [05:37<05:41,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.035017, test_loss 0.033516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 33/70 [05:46<05:33,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.040842, test_loss 0.027822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 34/70 [05:55<05:22,  8.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.026802, test_loss 0.034690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 35/70 [06:03<05:11,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.031227, test_loss 0.032966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 36/70 [06:13<05:04,  8.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.029394, test_loss 0.026589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 37/70 [06:22<04:56,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.023291, test_loss 0.023176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 38/70 [06:31<04:47,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.028275, test_loss 0.016254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 39/70 [06:40<04:40,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.035952, test_loss 0.021916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 40/70 [06:49<04:29,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.027332, test_loss 0.031935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 41/70 [06:57<04:19,  8.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.027638, test_loss 0.024185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 42/70 [07:06<04:09,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.034612, test_loss 0.033714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 43/70 [07:15<04:02,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.037673, test_loss 0.036998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 44/70 [07:24<03:54,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.025921, test_loss 0.027219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 45/70 [07:34<03:46,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.035055, test_loss 0.033694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 46/70 [07:43<03:36,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.039132, test_loss 0.034592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 47/70 [07:52<03:27,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.030559, test_loss 0.043854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 48/70 [08:01<03:18,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.040055, test_loss 0.058118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 49/70 [08:10<03:09,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.036201, test_loss 0.031701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 50/70 [08:19<03:01,  9.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.030731, test_loss 0.034847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 51/70 [08:28<02:52,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.032367, test_loss 0.020985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 52/70 [08:37<02:43,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.029263, test_loss 0.031469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 53/70 [08:46<02:34,  9.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.028696, test_loss 0.040443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 54/70 [08:55<02:25,  9.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.030074, test_loss 0.020960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 55/70 [09:04<02:16,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.028857, test_loss 0.033286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 56/70 [09:13<02:05,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.025363, test_loss 0.035735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 57/70 [09:22<01:57,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.033249, test_loss 0.028658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 58/70 [09:32<01:49,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.025847, test_loss 0.032108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 59/70 [09:41<01:40,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.023660, test_loss 0.047173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 60/70 [09:50<01:30,  9.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.027214, test_loss 0.039433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 61/70 [09:59<01:21,  9.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.032718, test_loss 0.040905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 62/70 [10:08<01:12,  9.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.041829, test_loss 0.058767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 63/70 [10:17<01:03,  9.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.035090, test_loss 0.022790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 64/70 [10:26<00:54,  9.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.040146, test_loss 0.025614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 65/70 [10:35<00:45,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.037233, test_loss 0.063094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 66/70 [10:44<00:35,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.032645, test_loss 0.032771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 67/70 [10:53<00:27,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.024957, test_loss 0.030568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 68/70 [11:02<00:18,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.022731, test_loss 0.045407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 69/70 [11:11<00:09,  9.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.026247, test_loss 0.032394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [11:20<00:00,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.029018, test_loss 0.037255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 70\n",
    "BEST_MODEL_PATH = 'best_steering_model_xy.pth'\n",
    "best_loss = 1e9\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "epoch_list = []\n",
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, labels in iter(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = F.mse_loss(outputs, labels)\n",
    "        train_loss += float(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    for images, labels in iter(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = F.mse_loss(outputs, labels)\n",
    "        test_loss += float(loss)\n",
    "    test_loss /= len(test_loader)\n",
    "    \n",
    "    print('train loss %f, test_loss %f' % (train_loss, test_loss))\n",
    "    epoch_list.append(epoch) \n",
    "    train_loss_list.append(train_loss)\n",
    "    test_loss_list.append(test_loss)\n",
    "    if test_loss < best_loss:\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        best_loss = test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "損失(Loss)から学習が正常に動作しているか確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b3a2828>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(epoch_list, train_loss_list, '-b', label='train_loss_list')\n",
    "plt.plot(epoch_list, test_loss_list, '-r', label='test_loss')\n",
    "\n",
    "plt.xlabel(\"n iteration\")\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained, it will generate ``best_steering_model_xy.pth`` file which you can use for inferencing in the live demo notebook.\n",
    "\n",
    "(訳)学習が完了すると、Live demo notebookで推論に使う``best_steering_model_xy.pth``が生成されます。\n",
    "\n",
    "If you trained on a different machine other than JetBot, you'll need to upload this to the JetBot to the ``road_following`` example folder.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
