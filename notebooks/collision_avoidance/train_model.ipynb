{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collision Avoidance - Train Model(モデルの学習)\n",
    "\n",
    "Welcome to this host side Jupyter Notebook!  This should look familiar if you ran through the notebooks that run on the robot.  In this notebook we'll train our image classifier to detect two classes\n",
    "``free`` and ``blocked``, which we'll use for avoiding collisions.  For this, we'll use a popular deep learning library *PyTorch*\n",
    "\n",
    "[訳] このホスト側のJupyer notebookへようこそ(追加: 今回はJetBot内で学習する)。ロボットの中で実行されるノートブックを実行した場合、これはおなじ感じです。。このnotebookでは、avoiding collisionを使うために、``free``と``blocked``の2つのクラスを特定する画像分類(image classifier)を学習します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload and extract dataset(データセットの解凍をアップロード)\n",
    "\n",
    "この処理は、ローカルで学習するため、スキップ。\n",
    "\n",
    "Before you start, you should upload the ``dataset.zip`` file that you created in the ``data_collection.ipynb`` notebook on the robot.\n",
    "\n",
    "You should then extract this dataset by calling the command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a folder named ``dataset`` appear in the file browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset instance(データセットインスタンスを生成)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the ``ImageFolder`` dataset class available with the ``torchvision.datasets`` package.  We attach transforms from the ``torchvision.transforms`` package to prepare the data for training.  \n",
    "\n",
    "(訳) ``torchvision.datasets``パッケージに含まれる``ImageFolder`` dataset classを使用します。学習用のデータを準備するために、``torchvision.transforms``パッケージからtransformsを紐付けます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(\n",
    "    'dataset',\n",
    "    transforms.Compose([\n",
    "        transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train and test sets(学習用とテスト用にデータセットを分ける)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split the dataset into *training* and *test* sets.  The test set will be used to verify the accuracy of the model we train.\n",
    "\n",
    "(訳) 次に、*training*用と*test*用のセットにデータセットをわけます。テストは、学習したモデルの精度を検証するために使用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - 50, 50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data loaders to load data in batches(バッチでデータをロードするためのデータローダーの作成)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create two ``DataLoader`` instances, which provide utilities for shuffling data, producing *batches* of images, and loading the samples in parallel with multiple workers.\n",
    "\n",
    "(訳) 2つの `` DataLoader``インスタンスを作成します。これらのインスタンスは、データのシャッフル、画像の*バッチ*の生成、および複数のワーカーと並行してサンプルをロードするためのユーティリティを提供します\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the neural network(Neural networkの定義)\n",
    "\n",
    "Now, we define the neural network we'll be training.  The *torchvision* package provides a collection of pre-trained models that we can use.\n",
    "\n",
    "(訳) 学習するためのneural networkを定義します。*torchvision*パッケージで、使用可能な学習済みモデルのコレクションが提供されています。\n",
    "\n",
    "In a process called *transfer learning*, we can repurpose a pre-trained model (trained on millions of images) for a new task that has possibly much less data available.\n",
    "\n",
    "(訳)*転移学習*と呼ばれる手法で、利用可能なデータがはるかに少ない状態で新しいタスクをおこなうために、事前にトレーニングされたモデル（数百万の画像でトレーニングされた）を再利用する事ができます。\n",
    "\n",
    "Important features that were learned in the original training of the pre-trained model are re-usable for the new task.  We'll use the ``alexnet`` model.\n",
    "\n",
    "(訳) 事前にトレーニング済みモデルで学習した重要な機能は、新しいタスクで再利用できます。 今回は、`` alexnet``モデルを使用します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``alexnet`` model was originally trained for a dataset that had 1000 class labels, but our dataset only has two class labels!  We'll replace\n",
    "the final layer with a new, untrained layer that has only two outputs.  \n",
    "\n",
    "(訳) ``alexnet``モデルは、1000クラスのラベルを持つデータセットを独自に学習させたものですが、我々のデータセットは、2クラスのラベルしか持っていません。\n",
    "出力が2つしかなく、トレーニングされていない新しいレイヤーを含む最終レイヤーを入れ替えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we transfer our model for execution on the GPU\n",
    "\n",
    "(訳) GPUの実行するために、モデルを転送します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the neural network(Nueral networkでの学習)\n",
    "\n",
    "Using the code below we will train the neural network for 30 epochs, saving the best performing model after each epoch.\n",
    "\n",
    "(訳) 下記コードを使い、30エポック、nueral networkで学習します。それぞれのエポックの後に、最高のパフォーマンスモデルを保存していきます。\n",
    "\n",
    "> An epoch is a full run through our data.\n",
    "\n",
    "> エポックとは、データを完全に把握することです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 30\n",
    "BEST_MODEL_PATH = 'best_model.pth'\n",
    "best_accuracy = 0.0\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    for images, labels in iter(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    test_error_count = 0.0\n",
    "    for images, labels in iter(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        test_error_count += float(torch.sum(torch.abs(labels - outputs.argmax(1))))\n",
    "    \n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_dataset))\n",
    "    print('%d: %f' % (epoch, test_accuracy))\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        best_accuracy = test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once that is finished, you should see a file ``best_model.pth`` in the Jupyter Lab file browser.  Select ``Right click`` -> ``Download`` to download the model to your workstation\n",
    "\n",
    "(訳) 学習が終わると、Jupyer Labのファイルブラウザに``best_model.pth``が生成されます。\n",
    "\n",
    "ローカルでの学習のためDownload処理は実施しなくて大丈夫です。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
