{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WR9BMrwsYCyz"
   },
   "source": [
    "# Road Following - Live demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q9M0kBRPYCy5"
   },
   "source": [
    "In this notebook, we will use model we trained to move jetBot smoothly on track. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GMd7QyzVYCy_"
   },
   "source": [
    "### Load Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iufm4e79YCzD"
   },
   "source": [
    "Execute the code below to initialize the PyTorch model. This should look very familiar from the training notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AHWL9A8JYCzJ"
   },
   "source": [
    "First, create the model. This must match the model used in the interactive training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wYC52Ff4YCzR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch2trt import TRTModule\n",
    "\n",
    "# TensorRTで最適化したモデルの型を取得\n",
    "model_trt = TRTModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "road_following_model_test2.pth\troad_following_model_trt_test2.pth\n",
      "road_following_model_trt2.pth\n"
     ]
    }
   ],
   "source": [
    "! ls nvidia_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZuFQeCPHYCzj"
   },
   "source": [
    "Next, load the trained weights from the ``road_following_model_trt.pth`` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DGJbalmkYCzm"
   },
   "outputs": [],
   "source": [
    "# モデルの重みを取得し、TensorRTで最適化したモデルに設定\n",
    "# model_trt.load_state_dict(torch.load('road_following_model_B2_trt.pth'))\n",
    "model_trt.load_state_dict(torch.load('nvidia_model/best_steering_model_xy_merged_trt.pth'))\n",
    "# デバイスを取得\n",
    "device = torch.device('cuda')\n",
    "# モデルをGPU用に変更\n",
    "model = model_trt.to(device)\n",
    "# モデルを評価用に変更.予測精度はFP16で行えると判断して設定\n",
    "# model = model_trt.eval().half()\n",
    "model = model_trt.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l0KGeUicYCzz"
   },
   "source": [
    "### Creating the Pre-Processing Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m_NBSvB3YCz2"
   },
   "source": [
    "We have now loaded our model, but there's a slight issue. The format that we trained our model doesnt exactly match the format of the camera. To do that, we need to do some preprocessing. This involves the following steps:\n",
    "\n",
    "1. Convert from HWC layout to CHW layout\n",
    "2. Normalize using same parameters as we did during training (our camera provides values in [0, 255] range and training loaded images in [0, 1] range so we need to scale by 255.0\n",
    "3. Transfer the data from CPU memory to GPU memory\n",
    "4. Add a batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hUYZb6rpYCz6"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "# RGBを正規化するための平均と分散を設定\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "# mean = torch.Tensor([0.485, 0.456, 0.406]).cuda()\n",
    "# std = torch.Tensor([0.229, 0.224, 0.225]).cuda()\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    # FP16の精度でPyTorchで扱えるデータ形式（Tensor）で変換し、さらにGPUで予測可能なデータに変換\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    # image = transforms.functional.to_tensor(image).to(device)\n",
    "    # 平均と分散で正規化\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yjNBR7laYC0I"
   },
   "source": [
    "Awesome! We've now defined our pre-processing function which can convert images from the camera format to the neural network input format.\n",
    "\n",
    "Now, let's start and display our camera. You should be pretty familiar with this by now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lEGCkhvGYC0M"
   },
   "outputs": [],
   "source": [
    "from jetcam.csi_camera import CSICamera\n",
    "\n",
    "camera = CSICamera(width=224, height=224)\n",
    "\n",
    "camera.running = True\n",
    "\n",
    "camera.unobserve_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HsjLnllcYC0a"
   },
   "source": [
    "We'll also create our robot instance which we'll need to drive the motors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1AXHtrtcYC0f"
   },
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "\n",
    "# JetBotを動作するためのオブジェクト\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rbQSJClIYC0s"
   },
   "source": [
    "Now, we will define sliders to control JetBot\n",
    "> Note: We have initialize the slider values for best known configurations, however these might not work for your dataset, therefore please increase or decrease the sliders according to your setup and environment\n",
    "\n",
    "1. Speed Control (speed_gain_slider): To start your JetBot increase ``speed_gain_slider`` \n",
    "2. Steering Gain Control (steering_gain_sloder): If you see JetBot is woblling, you need to reduce ``steering_gain_slider`` till it is smooth\n",
    "3. Steering Bias control (steering_bias_slider): If you see JetBot is biased towards extreme right or extreme left side of the track, you should control this slider till JetBot start following line or track in the center.  This accounts for motor biases as well as camera offsets\n",
    "\n",
    "> Note: You should play around above mentioned sliders with lower speed to get smooth JetBot road following behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yFR7JBaDYC0w",
    "outputId": "0f57faee-4b70-4b2f-82ce-6a3efc0181ce"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d5db734bbc64cb1b93502dc030c1abc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='speed gain', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f2b4a5e4b74ff2ba5379ad94dad8c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.2, description='steering gain', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588472490b564100bc0b6736106eae20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering kd', max=0.5, step=0.001)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ab3751829543e68376e2acc9b4c777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering bias', max=0.3, min=-0.3, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets\n",
    "\n",
    "# JetBotの動作を調整するパラメータ\n",
    "# 速度を調整するパラメータ\n",
    "speed_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, description='speed gain')\n",
    "# 角度を調整するパラメータ（低いほど、安定するが曲がりづらい）\n",
    "steering_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.2, description='steering gain')\n",
    "# 前の角度の影響を調整するパラメータ（低いほど、新しく得られた値を優先する）\n",
    "steering_dgain_slider = ipywidgets.FloatSlider(min=0.0, max=0.5, step=0.001, value=0.0, description='steering kd')\n",
    "# 偏りを調整するパラメータ\n",
    "steering_bias_slider = ipywidgets.FloatSlider(min=-0.3, max=0.3, step=0.01, value=0.0, description='steering bias')\n",
    "\n",
    "display(speed_gain_slider, steering_gain_slider, steering_dgain_slider, steering_bias_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dvcLVxxQYC1V"
   },
   "source": [
    "Next, let's display some sliders that will let us see what JetBot is thinking.  The x and y sliders will display the predicted x, y values.\n",
    "\n",
    "The steering slider will display our estimated steering value.  Please remember, this value isn't the actual angle of the target, but simply a value that is\n",
    "nearly proportional.  When the actual angle is ``0``, this will be zero, and it will increase / decrease with the actual angle.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vPI94kQIYC1c",
    "outputId": "36b31411-595e-4062-d139-02e3a817aed6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d15eb192404e466b98b9d156e92b67b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatSlider(value=0.0, description='y', max=1.0, orientation='vertical'), FloatSlider(value=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de1a319cdb64e9b9a82718d0592718f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='x', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7821bf329f437fa3a366e767f30085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x座標を表示\n",
    "x_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='x')\n",
    "# y座標を表示\n",
    "y_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='y')\n",
    "# ぐらつきを表示\n",
    "steering_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='steering')\n",
    "# 速度を表示\n",
    "speed_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='speed')\n",
    "\n",
    "display(ipywidgets.HBox([y_slider, speed_slider]))\n",
    "display(x_slider, steering_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mtU2dm9fYC1o"
   },
   "source": [
    "Setting Data object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uA4uEOAAYC1q"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from xy_dataset import XYDataset\n",
    "\n",
    "TASK = 'road_following'\n",
    "\n",
    "CATEGORIES = ['apex']\n",
    "\n",
    "DATASETS = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
    "\n",
    "TRANSFORMS = transforms.Compose([\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "datasets = {}\n",
    "for name in DATASETS:\n",
    "    datasets[name] = XYDataset(TASK + '_' + name, CATEGORIES, TRANSFORMS, random_hflip=True)\n",
    "    \n",
    "# データセットによってインデックスを変える必要があるので注意が必要。データセットがAの場合はインデックスは0\n",
    "dataset = datasets[DATASETS[2]]\n",
    "category_widget = ipywidgets.Dropdown(options=dataset.categories, description='category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8K0Z3DFQYC1v"
   },
   "source": [
    "### Live Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "33AvQlPVYC1w"
   },
   "source": [
    "Next, we'll create a function that will get called whenever the camera's value changes. This function will do the following steps\n",
    "\n",
    "1. Pre-process the camera image\n",
    "2. Execute the neural network\n",
    "3. Compute the approximate steering value\n",
    "4. Control the motors using proportional / derivative control (PD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uGNDi3cXYC1z",
    "outputId": "ad513869-33ce-4c3a-c5ea-752b3ad31b9e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be72d42598d941c3a190c659756e1857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Image(value=b'', format='jpeg', height='224', width='224'),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from jetbot import bgr8_to_jpeg\n",
    "import threading\n",
    "\n",
    "prediction_widget = ipywidgets.Image(format='jpeg', width=camera.width, height=camera.height)\n",
    "\n",
    "angle = 0.0\n",
    "angle_last = 0.0\n",
    "\n",
    "# 予測結果の画面を表示\n",
    "live_execution_widget = ipywidgets.VBox([\n",
    "    prediction_widget\n",
    "])\n",
    "\n",
    "display(live_execution_widget)\n",
    "\n",
    "while True:\n",
    "    image = camera.value\n",
    "    preprocessed = preprocess(image)\n",
    "    output = model(preprocessed).detach().cpu().numpy().flatten()\n",
    "    category_index = dataset.categories.index(category_widget.value)\n",
    "    x = output[2 * category_index]\n",
    "    y = output[2 * category_index + 1]\n",
    "\n",
    "    # 予測値をカメラのスケールに変換、中央からの値にしたいため、2で割って0.5を足している\n",
    "    x = int(camera.width * (x / 2.0 + 0.5))\n",
    "    y = int(camera.height * (y / 2.0 + 0.5))\n",
    "\n",
    "    prediction = image.copy()\n",
    "    prediction = cv2.circle(prediction, (x, y), 8, (255, 0, 0), 3)\n",
    "    prediction_widget.value = bgr8_to_jpeg(prediction)\n",
    "    \n",
    "    x = output[0]\n",
    "    y = (0.5 - output[1]) / 2.0\n",
    "    \n",
    "    # スライドバーに反映\n",
    "    x_slider.value = x\n",
    "    y_slider.value = y\n",
    "\n",
    "    # 設定した速度を反映\n",
    "    speed_slider.value = speed_gain_slider.value\n",
    "\n",
    "    # 曲がる角度を計算\n",
    "    angle = np.arctan2(x, y)\n",
    "    # 現在導出された角度とひとつ前の角度からの差分を導出\n",
    "    pid = angle * steering_gain_slider.value + (angle - angle_last) * steering_dgain_slider.value\n",
    "    # 角度を保存\n",
    "    angle_last = angle\n",
    "\n",
    "    # 曲がる値を表示\n",
    "    steering_slider.value = pid + steering_bias_slider.value\n",
    "\n",
    "    # 1.0を超えないように左右のモーターに値を設定。\n",
    "    robot.left_motor.value = max(min(speed_slider.value + steering_slider.value, 1.0), 0.0)\n",
    "    robot.right_motor.value = max(min(speed_slider.value - steering_slider.value, 1.0), 0.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2trfI08qYC14"
   },
   "source": [
    "Cool! We've created our neural network execution function, but now we need to attach it to the camera for processing.\n",
    "\n",
    "We accomplish that with the observe function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NktIzPr9YC16"
   },
   "source": [
    ">WARNING: This code will move the robot!! Please make sure your robot has clearance and it is on Lego or Track you have collected data on. The road follower should work, but the neural network is only as good as the data it's trained on!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CTp_7OeAYC18"
   },
   "source": [
    "Awesome! If your robot is plugged in it should now be generating new commands with each new camera frame. \n",
    "\n",
    "You can now place JetBot on  Lego or Track you have collected data on and see whether it can follow track.\n",
    "\n",
    "If you want to stop this behavior, you can unattach this callback by executing the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z5gZJwEfYC19"
   },
   "outputs": [],
   "source": [
    "# カメラの観測を終了してロボットを停止\n",
    "camera.unobserve_all()\n",
    "robot.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QVjsMCbUYC2C"
   },
   "source": [
    "### Conclusion\n",
    "That's it for this live demo! Hopefully you had some fun seeing your JetBot moving smoothly on track follwing the road!!!\n",
    "\n",
    "If your JetBot wasn't following road very well, try to spot where it fails. The beauty is that we can collect more data for these failure scenarios and the JetBot should get even better :)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "live_demo.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
